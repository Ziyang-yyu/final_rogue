{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "BOARD_ROWS = 4\n",
    "BOARD_COLS = 4\n",
    "TREASURE = (0,0)\n",
    "TREASURE = (1,2)\n",
    "DETERMINISTIC = False\n",
    "class State:\n",
    "    def __init__(self, p1, p2, state1 = (3,0), state2 = (3,1)):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        # init p1 plays first\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "        # closed doors\n",
    "        self.board[0,1] = -1\n",
    "        self.board[1,1] = -1\n",
    "        self.board[3,2] = -1\n",
    "\n",
    "        # starting pos\n",
    "        self.board[3,1] =  2\n",
    "        self.board[3,0] = 1\n",
    "\n",
    "\n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "\n",
    "    def winner(self):\n",
    "        # p1:1, p2:-1\n",
    "        if np.where(self.board == 1) == WIN_STATE:\n",
    "            return 1\n",
    "        elif np.where(self.board == 2) == WIN_STATE:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def isEndFunc(self):\n",
    "        if np.where(self.board == 1) == WIN_STATE or np.where(self.board == 2) == WIN_STATE:\n",
    "            self.isEnd = True\n",
    "\n",
    "    '''\n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))  # need to be tuple\n",
    "        return positions\n",
    "\n",
    "\n",
    "    '''\n",
    "    def updateState(self, curr_pos, position):\n",
    "        self.board[curr_pos] = 0\n",
    "        self.board[position] = self.playerSymbol\n",
    "        # switch to another player\n",
    "        self.playerSymbol = 2 if self.playerSymbol == 1 else 1\n",
    "\n",
    "\n",
    "    def _chooseActionProb(self, action):\n",
    "        if action == \"up\":\n",
    "            return np.random.choice([\"up\", \"left\", \"right\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"down\":\n",
    "            return np.random.choice([\"down\", \"left\", \"right\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"left\":\n",
    "            return np.random.choice([\"left\", \"up\", \"down\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"right\":\n",
    "            return np.random.choice([\"right\", \"up\", \"down\"], p=[0.8, 0.1, 0.1])\n",
    "\n",
    "    def nxtPosition(self, action):\n",
    "        \"\"\"\n",
    "        action: up, down, left, right\n",
    "        -------------\n",
    "        0 | 1 | 2| 3|\n",
    "        1 |\n",
    "        2 |\n",
    "        3 |\n",
    "        return next position on board\n",
    "        \"\"\"\n",
    "        if self.playerSymbol == 1:\n",
    "            #p1 turn\n",
    "            curr_state = np.where(self.board == 1)\n",
    "            oppo_state = np.where(self.board == 2)\n",
    "            curr_determine = self.p1.determine\n",
    "\n",
    "        else:\n",
    "            curr_state = np.where(self.board == 2)\n",
    "            oppo_state = np.where(self.board == 1)\n",
    "            curr_determine = self.p2.determine\n",
    "\n",
    "        if curr_determine:\n",
    "            if action == \"up\":\n",
    "                nxtState = (curr_state[0] - 1, curr_state[1])\n",
    "            elif action == \"down\":\n",
    "                nxtState = (curr_state[0] + 1, curr_state[1])\n",
    "            elif action == \"left\":\n",
    "                nxtState = (curr_state[0], curr_state[1] - 1)\n",
    "            else:\n",
    "                nxtState = (curr_state[0], curr_state[1] + 1)\n",
    "            curr_determine = False\n",
    "        else:\n",
    "            # non-deterministic\n",
    "            action = self._chooseActionProb(action)\n",
    "            curr_determine = True\n",
    "            nxtState = self.nxtPosition(action)\n",
    "\n",
    "        # if next state is legal\n",
    "        if (nxtState[0] >= 0) and (nxtState[0] <= 3):\n",
    "            if (nxtState[1] >= 0) and (nxtState[1] <= 3):\n",
    "                if nxtState != oppo_state and nxtState != (0, 1) and nxtState != (1, 1) and nxtState != (3, 2):\n",
    "                    # switch to another player\n",
    "                    self.playerSymbol = 2 if self.playerSymbol == 1 else 1\n",
    "                    return nxtState\n",
    "        return curr_state\n",
    "\n",
    "\n",
    "    # only when game ends\n",
    "    def giveReward(self):\n",
    "        if np.where(self.board == 1) == TREASURE:\n",
    "            self.p1.feedReward(1)\n",
    "        elif np.where(self.board == 1) == WIN_STATE:\n",
    "             self.p1.feedReward(0.8)\n",
    "        else:\n",
    "             self.p1.feedReward(0.1)\n",
    "\n",
    "        if np.where(self.board == 2) == TREASURE:\n",
    "            self.p2.feedReward(1)\n",
    "        elif np.where(self.board == 2) == WIN_STATE:\n",
    "             self.p2.feedReward(0.8)\n",
    "        else:\n",
    "            self.p2.feedReward(0.5)\n",
    "\n",
    "\n",
    "    # board reset\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "        # closed doors\n",
    "        self.board[0,1] = -1\n",
    "        self.board[1,1] = -1\n",
    "        self.board[3,2] = -1\n",
    "\n",
    "        # starting pos\n",
    "        self.board[3,0] = 1\n",
    "        self.board[3,1] = 2\n",
    "\n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                p1_action = self.p1.chooseAction(self.playerSymbol)\n",
    "                # take action and upate board state\n",
    "                self.updateState(np.where(self.board == 1), p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "\n",
    "\n",
    "                win = self.winner()\n",
    "                if win != 0:\n",
    "                    # game ended\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "\n",
    "                    p2_action = self.p2.chooseAction(self.playerSymbol)\n",
    "                    #self.updateState(p2_action)\n",
    "                    self.updateState(np.where(self.board == 2), p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.winner()\n",
    "                    if win != 0:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "\n",
    "    # play with human\n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            #positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(self.playerSymbol)\n",
    "            # take action and upate board state\n",
    "            self.updateState(np.where(self.board == 1), p1_action)\n",
    "            self.showBoard()\n",
    "            # check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win != 0:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(self.p1.name,\"lost!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "\n",
    "                p2_action = self.p2.chooseAction(self.playerSymbol)\n",
    "\n",
    "                self.updateState(np.where(self.board == 2), p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win != 0:\n",
    "                    print(self.p2.name, \"wins!\")\n",
    "                else:\n",
    "                    print(self.p2.name,\"lost!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == 2:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                if self.board[i,j] == -1:\n",
    "                    token = '1'\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []  # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}  # state -> value\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        self.determine = DETERMINISTIC\n",
    "\n",
    "         # initial Q values\n",
    "\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                self.states_value[(i, j)] = {}\n",
    "                for a in self.actions:\n",
    "                    self.states_value[(i, j)][a] = 0  # Q value is a dict of dict\n",
    "\n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return boardHash\n",
    "\n",
    "    def chooseAction(self, symbol):\n",
    "        # choose action with most expected value\n",
    "        mx_nxt_reward = 0\n",
    "        action = \"\"\n",
    "\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # greedy action\n",
    "            for a in self.actions:\n",
    "                current_position = self.State.state\n",
    "                nxt_reward = self.states_values[current_position][a]\n",
    "                if nxt_reward >= mx_nxt_reward:\n",
    "                    action = a\n",
    "                    mx_nxt_reward = nxt_reward\n",
    "            # print(\"current pos: {}, greedy aciton: {}\".format(self.State.state, action))\n",
    "        return action\n",
    "\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    def savePolicy(self):\n",
    "        fw = open('qpolicy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "\n",
    "\n",
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Rounds 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Player' object has no attribute 'State'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-58c1246ceace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# play with human\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0bc244ef05bd>\u001b[0m in \u001b[0;36mplay\u001b[1;34m(self, rounds)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misEnd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;31m# Player 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[0mp1_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchooseAction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayerSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[1;31m# take action and upate board state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0bc244ef05bd>\u001b[0m in \u001b[0;36mchooseAction\u001b[1;34m(self, symbol)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;31m# greedy action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m                 \u001b[0mcurrent_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m                 \u001b[0mnxt_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnxt_reward\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmx_nxt_reward\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Player' object has no attribute 'State'"
     ]
    }
   ],
   "source": [
    "    # training\n",
    "p1 = Player(\"p1\")\n",
    "p2 = Player(\"p2\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(50000)\n",
    "\n",
    "    # play with human\n",
    "p1 = Player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"qpolicy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
